# -*- coding: utf-8 -*-
"""Gestures.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1du3ltUiucdBNKeoKwBLtllNkHZ-GsYzW
"""

import os
import tensorflow as tf
import random
import pandas as pd
import numpy as np
from sklearn.preprocessing import MinMaxScaler
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense, Dropout, Bidirectional
from sklearn.model_selection import train_test_split
from sklearn.metrics import confusion_matrix, accuracy_score
import seaborn as sns
import matplotlib.pyplot as plt

from google.colab import drive

drive.mount('/content/drive')

directory = '/content/drive/My Drive/Data/'

double_tap_sequences = []
single_tap_sequences = []
no_tap_sequences = []

for filename in os.listdir(directory + 'DOUBLE_TAP_DATA'):
    if filename.endswith(".csv"):
        filepath = os.path.join(directory + 'DOUBLE_TAP_DATA', filename)
        df = pd.read_csv(filepath)

        #RawCount values from the dataset
        raw_counts = df['Proximity0_Sns0 RawCount'].values

        #Append the raw counts to the double tap sequences
        double_tap_sequences.append(raw_counts)

# Single tap gestures
for filename in os.listdir(directory + 'SINGLE_TAP_DATA'):
    if filename.endswith(".csv"):
        filepath = os.path.join(directory + 'SINGLE_TAP_DATA', filename)
        df = pd.read_csv(filepath)

        raw_counts = df['Proximity0_Sns0 RawCount'].values
        single_tap_sequences.append(raw_counts)

# No tap gestures
for filename in os.listdir(directory + 'NO_TAP_DATA'):
    if filename.endswith(".csv"):
        filepath = os.path.join(directory + 'NO_TAP_DATA', filename)
        df = pd.read_csv(filepath)

        raw_counts = df['Proximity0_Sns0 RawCount'].values
        no_tap_sequences.append(raw_counts)

from tensorflow.keras.preprocessing.sequence import pad_sequences

# Pad sequences to ensure they are all of length 100
double_tap_sequences = pad_sequences(double_tap_sequences, maxlen=100, padding='post')
single_tap_sequences = pad_sequences(single_tap_sequences, maxlen=100, padding='post')
no_tap_sequences = pad_sequences(no_tap_sequences, maxlen=100, padding='post')

#lists to np arrays
double_tap_sequences = np.array(double_tap_sequences).reshape((50, 100, 1))
single_tap_sequences = np.array(single_tap_sequences).reshape((50, 100, 1))
no_tap_sequences = np.array(no_tap_sequences).reshape((50, 100, 1))

#combining all gesture sequences
X = np.concatenate([double_tap_sequences, single_tap_sequences, no_tap_sequences], axis=0)

#labels for each gesture type

y_double_tap = np.ones(50)  # 1 for double tap
y_single_tap = np.zeros(50)  # 0 for single tap
y_no_tap = 2 * np.ones(50)  # 2 for no tap

#combining the labels into a single array
y = np.concatenate([y_double_tap, y_single_tap, y_no_tap], axis=0)

#normalize data to 3d format to fed in the NN
scaler = MinMaxScaler()
X = scaler.fit_transform(X.reshape(-1, 100)).reshape(-1, 100, 1)

#converting labels to categorical (one-hot encoding)
from tensorflow.keras.utils import to_categorical

y = to_categorical(y, num_classes=3)

#spliting data into training and test sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)

#shifting function
def shift_data(data, max_shift=5):
    shift = random.randint(-max_shift, max_shift)
    return np.roll(data, shift, axis=1)

#scaling function
def scale_data(data, scale_factor=0.01):
    scale = np.random.uniform(1 - scale_factor, 1 + scale_factor)
    return data * scale

# Data Augmentation function to add random noise
def augment_data(data, noise_factor=0.01, max_shift=5, scale_factor=0.01):
  noisy_data = data + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=data.shape)
  shifted_data = shift_data(noisy_data, max_shift=max_shift)
  scaled_data = scale_data(shifted_data, scale_factor=scale_factor)
  return scaled_data

# Augmented training data
X_train_augmented = augment_data(X_train)

#combining original and augmented data
X_train_combo = np.concatenate([X_train, X_train_augmented], axis = 0)
y_train_combo = np.concatenate([y_train, y_train], axis = 0)  # Labels remain the same

print("X_train_combo shape:", X_train_combo.shape)
print("y_train_combo shape:", y_train_combo.shape)
print("X_test shape:", X_test.shape)
print("y_test shape:", y_test.shape)

from sklearn.model_selection import StratifiedKFold

# Number of folds for cross-validation
k = 5
skf = StratifiedKFold(n_splits=k, shuffle=True, random_state=42)

#data to numpy arrays
X_data = np.array(X_train_combo)
y_data = np.array(y_train_combo)

#storing accuracy and confusion matrix for each fold
accuracy_per_fold = []
confusion_matrices = []

# Iterating over each fold
fold_no = 1
for train_index, val_index in skf.split(X_data, np.argmax(y_data, axis=1)):
    # Spliting the data into training and validation sets
    X_train, X_val = X_data[train_index], X_data[val_index]
    y_train, y_val = y_data[train_index], y_data[val_index]

    # Model Architecture
    model = Sequential()
    model.add(Bidirectional(tf.keras.layers.LSTM(128, return_sequences=True, input_shape=(100, 1))))
    model.add(Dropout(0.3))
    model.add(Bidirectional(tf.keras.layers.LSTM(64, return_sequences=False)))
    model.add(Dropout(0.3))
    model.add(Dense(64, activation='relu'))
    model.add(Dense(3, activation='softmax'))


    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

    # Model training
    history = model.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_val, y_val), verbose=0)

    # Evaluate Model on the validation set
    scores = model.evaluate(X_val, y_val, verbose=0)
    print(f'Score for fold {fold_no}: {model.metrics_names[1]} of {scores[1]*100}%')

    accuracy_per_fold.append(scores[1] * 100)

    # Predict on validation set
    y_pred = model.predict(X_val)
    y_pred_classes = np.argmax(y_pred, axis=1)  # Convert one-hot encoding to class labels
    y_true_classes = np.argmax(y_val, axis=1)   # Convert one-hot encoding to class labels

    # Compute confusion matrix
    cm = confusion_matrix(y_true_classes, y_pred_classes)
    confusion_matrices.append(cm)

    # Plot the confusion matrix for each fold
    plt.figure(figsize=(6,4))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['No Tap', 'Single Tap', 'Double Tap'], yticklabels=['No Tap', 'Single Tap', 'Double Tap'])
    plt.title(f'Confusion Matrix for Fold {fold_no}')
    plt.xlabel('Predicted Labels')
    plt.ylabel('True Labels')
    plt.show()

    fold_no += 1

# Print the model architecture in text format
model.summary()

from tensorflow.keras.utils import plot_model

# Save and display the model architecture
plot_model(model, to_file='bi_lstm_model.png', show_shapes=True, show_layer_names=True, dpi=100)

#Overall accuracy
print(f'\nAverage accuracy across {k} folds: {np.mean(accuracy_per_fold)}%')

#Evaluation
loss, accuracy = model.evaluate(X_test, y_test)
print(f'LSTM Accuracy: {accuracy * 100:.2f}%')

# Saving the trained model
model.save("Gesture_detection_model.h5")

import os

# Get the file size in bytes
file_size = os.path.getsize('Gesture_detection_model.h5')
print(f"Model size: {file_size / (1024 * 1024):.2f} MB")